{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize_scalar\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestMSE:\n",
    "    def __init__(\n",
    "        self, n_estimators, max_depth=None, feature_subsample_size=None,\n",
    "        **trees_parameters\n",
    "    ):\n",
    "        \"\"\"\n",
    "        n_estimators : int\n",
    "            The number of trees in the forest.\n",
    "        max_depth : int\n",
    "            The maximum depth of the tree. If None then there is no limits.\n",
    "        feature_subsample_size : float\n",
    "            The size of feature set for each tree. If None then use one-third of all features.\n",
    "        \"\"\"\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.feature_subsample_size = feature_subsample_size\n",
    "        self.trees_parameters = trees_parameters\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        X : numpy ndarray\n",
    "            Array of size n_objects, n_features\n",
    "        y : numpy ndarray\n",
    "            Array of size n_objects\n",
    "        X_val : numpy ndarray\n",
    "            Array of size n_val_objects, n_features\n",
    "        y_val : numpy ndarray\n",
    "            Array of size n_val_objects\n",
    "        \"\"\"\n",
    "        if self.feature_subsample_size is None:\n",
    "            self.feature_subsample_size = X.shape[1] // 3\n",
    "        \n",
    "        history = {'loss_train': [], 'loss_val': []}\n",
    "        \n",
    "        self.forest = []\n",
    "        all_features = list(range(1, X.shape[1]))\n",
    "        self.tree_features = []\n",
    "        res_train = np.zeros(X.shape[0])\n",
    "        if X_val is not None:\n",
    "            res_val = np.zeros(X_val.shape[0])\n",
    "        for i in range(self.n_estimators):\n",
    "            tree = DecisionTreeRegressor(max_depth = self.max_depth, **self.trees_parameters)\n",
    "            \n",
    "            boot_idx = np.random.randint(0, X.shape[0], X.shape[0])\n",
    "            random.shuffle(all_features)\n",
    "            \n",
    "            tree.fit(X[boot_idx][:, all_features[:self.feature_subsample_size]], y[boot_idx])\n",
    "            self.forest += [tree]\n",
    "            self.tree_features.append(all_features[:self.feature_subsample_size])\n",
    "            \n",
    "            \n",
    "            res_train += tree.predict(X[:, all_features[:self.feature_subsample_size]])\n",
    "            history['loss_train'].append(self.rmse( y, res_train/(i+1) ))\n",
    "            if X_val is not None:\n",
    "                res_val += tree.predict(X_val[:, all_features[:self.feature_subsample_size]])\n",
    "                history['loss_val'].append(self.rmse( y_val, res_val/(i+1) ))\n",
    "        return history\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        X : numpy ndarray\n",
    "            Array of size n_objects, n_features\n",
    "        Returns\n",
    "        -------\n",
    "        y : numpy ndarray\n",
    "            Array of size n_objects\n",
    "        \"\"\"\n",
    "        res = np.zeros(X.shape[0])\n",
    "        for i in range(len(self.forest)):\n",
    "            tree = self.forest[i]\n",
    "            features = self.tree_features[i]\n",
    "            res += tree.predict(X[:, features])\n",
    "        return res / len(self.forest)\n",
    "    \n",
    "    def rmse(self, y, y_pred):\n",
    "        return np.sqrt(((y - y_pred)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoostingMSE:\n",
    "    def __init__(\n",
    "        self, n_estimators, learning_rate=0.1, max_depth=5, feature_subsample_size=None,\n",
    "        **trees_parameters\n",
    "    ):\n",
    "        \"\"\"\n",
    "        n_estimators : int\n",
    "            The number of trees in the forest.\n",
    "        learning_rate : float\n",
    "            Use alpha * learning_rate instead of alpha\n",
    "        max_depth : int\n",
    "            The maximum depth of the tree. If None then there is no limits.\n",
    "        feature_subsample_size : float\n",
    "            The size of feature set for each tree. If None then use one-third of all features.\n",
    "        \"\"\"\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.feature_subsample_size = feature_subsample_size\n",
    "        self.trees_parameters = trees_parameters\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        X : numpy ndarray\n",
    "            Array of size n_objects, n_features\n",
    "        y : numpy ndarray\n",
    "            Array of size n_objects\n",
    "        \"\"\"\n",
    "        if self.feature_subsample_size is None:\n",
    "            self.feature_subsample_size = X.shape[1] // 3\n",
    "        \n",
    "        all_features = list(range(1, X.shape[1]))\n",
    "        history = {'loss_train': [], 'loss_val': []}\n",
    "        \n",
    "        tree = DecisionTreeRegressor(max_depth = self.max_depth, **self.trees_parameters)\n",
    "\n",
    "        random.shuffle(all_features)\n",
    "        \n",
    "        tree.fit(X[:, all_features[:self.feature_subsample_size]], y)\n",
    "        res = tree.predict(X[:, all_features[:self.feature_subsample_size]])\n",
    "        self.trees = [tree]\n",
    "        self.tree_features = [all_features[:self.feature_subsample_size]]\n",
    "        self.coef = [1]\n",
    "        \n",
    "        history['loss_train'].append(self.rmse(y, res))\n",
    "        if X_val is not None:\n",
    "            y_pred = self.predict(X_val)\n",
    "            history['loss_val'].append(self.rmse(y_val, y_pred))\n",
    "        \n",
    "        for i in range(self.n_estimators - 1):\n",
    "            tree = DecisionTreeRegressor(max_depth = self.max_depth, **self.trees_parameters)\n",
    "            anti_gradient = y - res\n",
    "            random.shuffle(all_features)\n",
    "            \n",
    "            tree.fit(X[:, all_features[:self.feature_subsample_size]], anti_gradient)\n",
    "            y_pred = tree.predict(X[:, all_features[:self.feature_subsample_size]])\n",
    "            self.coef += [minimize_scalar(lambda x: self.rmse(y, res + x*y_pred)).x]\n",
    "            res += self.learning_rate * self.coef[i] * y_pred\n",
    "            self.trees += [tree]\n",
    "            self.tree_features.append(all_features[:self.feature_subsample_size])\n",
    "            \n",
    "            history['loss_train'].append(self.rmse(y, res))\n",
    "            if X_val is not None:\n",
    "                y_pred = self.predict(X_val)\n",
    "                history['loss_val'].append(self.rmse(y_val, y_pred))\n",
    "        return history\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        X : numpy ndarray\n",
    "            Array of size n_objects, n_features\n",
    "        Returns\n",
    "        -------\n",
    "        y : numpy ndarray\n",
    "            Array of size n_objects\n",
    "        \"\"\"\n",
    "        features = self.tree_features[0]\n",
    "        res = self.trees[0].predict(X[:, features])\n",
    "        for i in range(1, len(self.trees)):\n",
    "            tree = self.trees[i]\n",
    "            features = self.tree_features[i]\n",
    "            res += self.learning_rate * self.coef[i] * tree.predict(X[:, features])\n",
    "        return res\n",
    "    \n",
    "    def rmse(self, y, y_pred):\n",
    "        return np.sqrt(((y - y_pred)**2).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
